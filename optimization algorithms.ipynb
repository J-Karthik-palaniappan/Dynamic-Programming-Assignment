{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "bIbBS7nMzuD0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,log_loss,accuracy_score\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZAMI_l5C2iH8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\JAYANKONDAN\\Downloads\\archive (3)\\Bank_Personal_Loan_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "bF_HPBv42saX",
    "outputId": "bcdff408-f16d-4a64-e853-0f61079a4509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxiWLfPA3dwT",
    "outputId": "6a3432c8-4ef9-46c6-ad68-c8fcf959d84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "data.drop(['ID','ZIP Code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x16c3321c490>,\n",
       "  <matplotlib.lines.Line2D at 0x16c3321c820>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x16c3321cbb0>,\n",
       "  <matplotlib.lines.Line2D at 0x16c3321cf40>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x16c3321c100>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x16c33225310>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x16c332256a0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(data['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Income']<=160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "hp-YP4g3JFPQ",
    "outputId": "31ad28c5-afa8-473f-ae0d-cbef342f9a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0:  93.48338692390139 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Personal Loan',data = data)\n",
    "print(\"class0: \",sum(data['Personal Loan']==0)/len(data)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Personal Loan',axis=1).values\n",
    "Y = data['Personal Loan'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSdljWla2_I-",
    "outputId": "865044dd-1b11-46d1-e23b-67cfb1d6dc46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3498, 11), (1167, 11), (3498,), (1167,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr,xtst,ytr,ytst = tts(X,Y,test_size=0.25,stratify=Y,random_state=42)\n",
    "xtr.shape,xtst.shape,ytr.shape,ytst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "xtr = sc.fit_transform(xtr)\n",
    "xtst = sc.transform(xtst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxqsCehJqqsa"
   },
   "source": [
    "# NN-from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn:\n",
    "    def __init__(self,ip,op):\n",
    "        self.ip=ip\n",
    "        self.op=op\n",
    "        print(ip.shape,op.shape)\n",
    "        self.l1_size=100\n",
    "        self.w1=np.random.rand(self.l1_size,self.ip.shape[1]+1).T*0.3-0.15\n",
    "        self.w2=np.random.rand(self.op.shape[1],self.l1_size+1).T*0.3-0.15\n",
    "        print(self.w1.shape,self.w2.shape)\n",
    "        for i in range(1000):\n",
    "            if i%10 == 0:print(i)\n",
    "            self.train()\n",
    "    \n",
    "    def sig(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def train(self):\n",
    "        #===front propogation===#\n",
    "        ip=np.append(np.ones((len(self.ip),1)),self.ip,axis=1)\n",
    "        l1=self.sig(ip@self.w1)\n",
    "        l1=np.append(np.ones((len(l1),1)),l1,axis=1)\n",
    "        pred=self.sig(l1@self.w2)\n",
    "        #===back propogation===#\n",
    "        #error at each layer\n",
    "        d3 = (pred - self.op)\n",
    "        d2 = (d3 @ self.w2.T * l1 * (1-l1))\n",
    "        d2 = d2[:,1:]\n",
    "        #altering weights\n",
    "        self.w2-= (l1.T @ d3)/len(ip)\n",
    "        self.w1-= (ip.T @ d2)/len(ip)\n",
    "        \n",
    "    def predict(self,ip):\n",
    "        ip=np.append(np.ones((len(ip),1)),ip,axis=1)\n",
    "        l1=self.sig(ip@self.w1)\n",
    "        l1=np.append(np.ones((len(l1),1)),l1,axis=1)\n",
    "        pred=self.sig(l1@self.w2)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 11) (3498, 1)\n",
      "(12, 100) (101, 1)\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "net = nn(xtr,ytr.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = (net.predict(xtst)>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1076,   25],\n",
       "       [  15,   51]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1101\n",
      "           1       0.67      0.77      0.72        66\n",
      "\n",
      "    accuracy                           0.97      1167\n",
      "   macro avg       0.83      0.88      0.85      1167\n",
      "weighted avg       0.97      0.97      0.97      1167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - Base for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn_base:\n",
    "    def __init__(self,ip_size):\n",
    "        print('creating NN BASE...')\n",
    "        self.weightstruct = []\n",
    "        self.ip_size = ip_size #number of features in input\n",
    "        self.act = []\n",
    "        \n",
    "    def addlayer(self,layer_size,activation):\n",
    "        self.act.append(activation)\n",
    "        if self.weightstruct == []:\n",
    "            self.weightstruct.append((self.ip_size+1,layer_size))\n",
    "        else:\n",
    "            prev = self.weightstruct[-1][-1]\n",
    "            self.weightstruct.append((prev+1,layer_size))\n",
    "            \n",
    "    def sig(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def ReLU(x):\n",
    "        return (x>0)*x\n",
    "    \n",
    "    def forward(self,ip,weights):\n",
    "        layer = ip\n",
    "        for i,j in zip(weights,self.act):\n",
    "            layer = np.append(np.ones((len(layer),1)),layer,axis=1) #bias layer\n",
    "            if j=='sigmoid':\n",
    "                layer = nn_base.sig(layer @ i) #linear combination and activation\n",
    "            else:\n",
    "                layer = nn_base.ReLU(layer @ i)\n",
    "        return layer\n",
    "    \n",
    "    def loss(pred,op):\n",
    "        #Absolute Error\n",
    "        return np.mean(abs(pred.flatten()-op.flatten()))\n",
    "    \n",
    "    def random_weights(self):\n",
    "        new = []\n",
    "        for i in self.weightstruct:\n",
    "            new.append(np.random.random(i)*3-0.15)\n",
    "        return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a customised nn from scratch where the user can add as many layers as they want. The back tracking is not done by gradient descent ,so the front propogation function is alone enough. ReLU and sigmoid are the only activation functions for now.\n",
    "This nn-base can be combined with any optimization function for backtracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating NN BASE...\n"
     ]
    }
   ],
   "source": [
    "base = nn_base(11) #input feature size 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 16), (17, 8), (9, 1)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.addlayer(16,'ReLU') #creating nn-structure\n",
    "base.addlayer(8,'sigmoid')\n",
    "base.addlayer(1,'sigmoid')\n",
    "base.weightstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of trainable parameters: (12 * 16) + (17 * 8) + (9 * 1) = 337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99995146],\n",
       "       [0.99995146],\n",
       "       [0.99995146],\n",
       "       ...,\n",
       "       [0.99995146],\n",
       "       [0.99942034],\n",
       "       [0.99995146]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.forward(xtr,base.random_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - Genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class genetic:\n",
    "    def __init__(self,base,pop_size):\n",
    "        print(\"GENETIC\")\n",
    "        self.base = base\n",
    "        self.pop_size = pop_size\n",
    "        self.population = [base.random_weights() for i in range(pop_size)]\n",
    "        self.gen = 0\n",
    "        \n",
    "    def move(self,xtr,ytr):\n",
    "        nextgen = self.population.copy()\n",
    "        for i in range(self.pop_size-1):\n",
    "            for j in range(i,self.pop_size):\n",
    "                p1 = self.population[i]\n",
    "                p2 = self.population[j]\n",
    "                c1,c2 = genetic.offspring(p1,p2)\n",
    "                nextgen.append(c1)\n",
    "                nextgen.append(c2)\n",
    "                \n",
    "        sortedgen = sorted(nextgen,key = lambda w : nn_base.loss(base.forward(xtr,w),ytr))\n",
    "        self.population = sortedgen[:self.pop_size]\n",
    "        \n",
    "        self.gen += 1\n",
    "        print(\"generation: %d | loss: %f\"%(self.gen,nn_base.loss(base.forward(xtr,self.population[0]),ytr)))\n",
    "                \n",
    "    def offspring(p1,p2):\n",
    "        c1 = []\n",
    "        c2 = []\n",
    "        for i in range(len(p1)):\n",
    "            a = p1[i]\n",
    "            b = p2[i]\n",
    "            \n",
    "            ind = np.random.randint(0,2,a.shape) #crossover\n",
    "            child1 = a*ind + b*(1^ind)\n",
    "            child2 = a*(1^ind) + b*ind\n",
    "            \n",
    "            child1 += (np.random.choice([0,1],child1.shape,p=[0.7,0.3]) * np.random.random(child1.shape)*2-0.5) #mutation\n",
    "            child1 += (np.random.choice([0,1],child1.shape,p=[0.7,0.3]) * np.random.random(child2.shape)*2-0.5)\n",
    "            \n",
    "            c1.append(child1)\n",
    "            c2.append(child2)\n",
    "        return c1,c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENETIC\n"
     ]
    }
   ],
   "source": [
    "gen = genetic(base,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 1 | loss: 0.764938\n",
      "generation: 2 | loss: 0.072761\n",
      "generation: 3 | loss: 0.065607\n",
      "generation: 4 | loss: 0.065320\n",
      "generation: 5 | loss: 0.065196\n",
      "generation: 6 | loss: 0.065181\n",
      "generation: 7 | loss: 0.065181\n",
      "generation: 8 | loss: 0.065127\n",
      "generation: 9 | loss: 0.065127\n",
      "generation: 10 | loss: 0.064975\n",
      "generation: 11 | loss: 0.064914\n",
      "generation: 12 | loss: 0.063479\n",
      "generation: 13 | loss: 0.062598\n",
      "generation: 14 | loss: 0.061296\n",
      "generation: 15 | loss: 0.059608\n",
      "generation: 16 | loss: 0.056453\n",
      "generation: 17 | loss: 0.055030\n",
      "generation: 18 | loss: 0.054132\n",
      "generation: 19 | loss: 0.052493\n",
      "generation: 20 | loss: 0.051522\n",
      "generation: 21 | loss: 0.050060\n",
      "generation: 22 | loss: 0.048145\n",
      "generation: 23 | loss: 0.046648\n",
      "generation: 24 | loss: 0.046619\n",
      "generation: 25 | loss: 0.045976\n",
      "generation: 26 | loss: 0.045596\n",
      "generation: 27 | loss: 0.044294\n",
      "generation: 28 | loss: 0.044280\n",
      "generation: 29 | loss: 0.043793\n",
      "generation: 30 | loss: 0.043793\n",
      "generation: 31 | loss: 0.043447\n",
      "generation: 32 | loss: 0.043154\n",
      "generation: 33 | loss: 0.043095\n",
      "generation: 34 | loss: 0.042964\n",
      "generation: 35 | loss: 0.042932\n",
      "generation: 36 | loss: 0.042913\n",
      "generation: 37 | loss: 0.042898\n",
      "generation: 38 | loss: 0.042883\n",
      "generation: 39 | loss: 0.042874\n",
      "generation: 40 | loss: 0.042857\n",
      "generation: 41 | loss: 0.042857\n",
      "generation: 42 | loss: 0.042857\n",
      "generation: 43 | loss: 0.042857\n",
      "generation: 44 | loss: 0.042857\n",
      "generation: 45 | loss: 0.042857\n",
      "generation: 46 | loss: 0.042857\n",
      "generation: 47 | loss: 0.042857\n",
      "generation: 48 | loss: 0.042857\n",
      "generation: 49 | loss: 0.042857\n",
      "generation: 50 | loss: 0.042857\n",
      "generation: 51 | loss: 0.042857\n",
      "generation: 52 | loss: 0.042857\n",
      "generation: 53 | loss: 0.042857\n",
      "generation: 54 | loss: 0.042857\n",
      "generation: 55 | loss: 0.042857\n",
      "generation: 56 | loss: 0.042857\n",
      "generation: 57 | loss: 0.042857\n",
      "generation: 58 | loss: 0.042857\n",
      "generation: 59 | loss: 0.042857\n",
      "generation: 60 | loss: 0.042857\n",
      "generation: 61 | loss: 0.042857\n",
      "generation: 62 | loss: 0.042857\n",
      "generation: 63 | loss: 0.042857\n",
      "generation: 64 | loss: 0.042857\n",
      "generation: 65 | loss: 0.042857\n",
      "generation: 66 | loss: 0.042857\n",
      "generation: 67 | loss: 0.042857\n",
      "generation: 68 | loss: 0.042857\n",
      "generation: 69 | loss: 0.042857\n",
      "generation: 70 | loss: 0.042857\n",
      "generation: 71 | loss: 0.042857\n",
      "generation: 72 | loss: 0.042857\n",
      "generation: 73 | loss: 0.042857\n",
      "generation: 74 | loss: 0.042857\n",
      "generation: 75 | loss: 0.042857\n",
      "generation: 76 | loss: 0.042857\n",
      "generation: 77 | loss: 0.042857\n",
      "generation: 78 | loss: 0.042857\n",
      "generation: 79 | loss: 0.042857\n",
      "generation: 80 | loss: 0.042857\n",
      "generation: 81 | loss: 0.042857\n",
      "generation: 82 | loss: 0.042857\n",
      "generation: 83 | loss: 0.042857\n",
      "generation: 84 | loss: 0.042857\n",
      "generation: 85 | loss: 0.042857\n",
      "generation: 86 | loss: 0.042857\n",
      "generation: 87 | loss: 0.042857\n",
      "generation: 88 | loss: 0.042857\n",
      "generation: 89 | loss: 0.042857\n",
      "generation: 90 | loss: 0.042857\n",
      "generation: 91 | loss: 0.042857\n",
      "generation: 92 | loss: 0.042857\n",
      "generation: 93 | loss: 0.042857\n",
      "generation: 94 | loss: 0.042857\n",
      "generation: 95 | loss: 0.042857\n",
      "generation: 96 | loss: 0.042857\n",
      "generation: 97 | loss: 0.042857\n",
      "generation: 98 | loss: 0.042857\n",
      "generation: 99 | loss: 0.042857\n",
      "generation: 100 | loss: 0.042857\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    gen.move(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1074,   39],\n",
       "       [  17,   37]], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = (base.forward(xtst,gen.population[0])>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1113\n",
      "           1       0.49      0.69      0.57        54\n",
      "\n",
      "    accuracy                           0.95      1167\n",
      "   macro avg       0.74      0.83      0.77      1167\n",
      "weighted avg       0.96      0.95      0.96      1167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5692307692307693"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytst,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - Particle swarm optimiztaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self,base,pop_size):\n",
    "        print(\"PARTICLE SWARM\")\n",
    "        self.base = base\n",
    "        self.pop_size = pop_size\n",
    "        self.population = [base.random_weights() for i in range(pop_size)]\n",
    "        self.gen = 0\n",
    "        self.personalbest = copy.deepcopy(self.population)\n",
    "        self.globalbest = self.population[0]\n",
    "        #self.velocity = [[np.zeros(j.shape) for j in self.globalbest] for i in range(pop_size)]\n",
    "        self.velocity = copy.deepcopy(self.population)\n",
    "        \n",
    "        self.w = 0.7\n",
    "        self.c1 = 1.4\n",
    "        self.c2 = 1.4\n",
    "        \n",
    "    def move(self,xtr,ytr):\n",
    "        self.update_values()\n",
    "        self.update_best(xtr,ytr)\n",
    "        self.gen += 1\n",
    "        \n",
    "    def update_values(self):\n",
    "        for ind in range(self.pop_size):\n",
    "            w = self.population[ind]\n",
    "            personalbest = self.personalbest[ind]\n",
    "            vel = self.velocity[ind]\n",
    "            for i in range(len(w)):\n",
    "                r1, r2 = np.random.rand(2)\n",
    "                vel[i] = self.w*vel[i] + self.c1*r1*(personalbest[i]-w[i]) + self.c2*r2*(self.globalbest[i]-w[i])\n",
    "                w[i] += vel[i]\n",
    "        \n",
    "    def update_best(self,xtr,ytr):\n",
    "        loss = lambda w : nn_base.loss(base.forward(xtr,w),ytr)\n",
    "        for ind in range(self.pop_size):\n",
    "            w = self.population[ind]\n",
    "            \n",
    "            if loss(w) < loss(self.personalbest[ind]): #updating personal best\n",
    "                self.personalbest[ind] = copy.deepcopy(w)\n",
    "                \n",
    "            if loss(self.personalbest[ind]) < loss(self.globalbest): #updating global best\n",
    "                self.globalbest = copy.deepcopy(self.personalbest[ind])\n",
    "                \n",
    "        print(\"generation: %d | loss: %f\"%(self.gen,loss(self.globalbest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTICLE SWARM\n"
     ]
    }
   ],
   "source": [
    "pso = PSO(base,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 0 | loss: 0.906205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/1634064413.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 1 | loss: 0.065180\n",
      "generation: 2 | loss: 0.065180\n",
      "generation: 3 | loss: 0.065176\n",
      "generation: 4 | loss: 0.065167\n",
      "generation: 5 | loss: 0.065022\n",
      "generation: 6 | loss: 0.064044\n",
      "generation: 7 | loss: 0.060001\n",
      "generation: 8 | loss: 0.060001\n",
      "generation: 9 | loss: 0.060001\n",
      "generation: 10 | loss: 0.059962\n",
      "generation: 11 | loss: 0.059962\n",
      "generation: 12 | loss: 0.059937\n",
      "generation: 13 | loss: 0.059290\n",
      "generation: 14 | loss: 0.058052\n",
      "generation: 15 | loss: 0.057352\n",
      "generation: 16 | loss: 0.055761\n",
      "generation: 17 | loss: 0.055648\n",
      "generation: 18 | loss: 0.053864\n",
      "generation: 19 | loss: 0.052727\n",
      "generation: 20 | loss: 0.051950\n",
      "generation: 21 | loss: 0.051508\n",
      "generation: 22 | loss: 0.049707\n",
      "generation: 23 | loss: 0.048645\n",
      "generation: 24 | loss: 0.046146\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    pso.move(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1083,   58],\n",
       "       [   8,   18]], dtype=int64)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = (base.forward(xtst,pso.globalbest)>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1141\n",
      "           1       0.24      0.69      0.35        26\n",
      "\n",
      "    accuracy                           0.94      1167\n",
      "   macro avg       0.61      0.82      0.66      1167\n",
      "weighted avg       0.98      0.94      0.96      1167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - Cultural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cultural(genetic):\n",
    "    def __init__(self,base,pop_size):\n",
    "        super().__init__(base,pop_size)\n",
    "        print('CULTURAL')\n",
    "        \n",
    "    def move(self,xtr,ytr):\n",
    "        nextgen = self.population.copy()\n",
    "        for i in range(self.pop_size-1):\n",
    "            for j in range(i,self.pop_size):\n",
    "                p1 = self.population[i]\n",
    "                p2 = self.population[j]\n",
    "                c1,c2 = genetic.offspring(p1,p2)\n",
    "                nextgen.append(c1)\n",
    "                nextgen.append(c2)\n",
    "                \n",
    "        sortedgen = sorted(nextgen,key = lambda w : nn_base.loss(base.forward(xtr,w),ytr))\n",
    "        self.population = sortedgen[:self.pop_size//2]\n",
    "        \n",
    "        cultfit = max(self.population,key = lambda w : self.culture_score(w,xtr,ytr))\n",
    "        self.population += self.culture_influence(self.population,cultfit)\n",
    "        \n",
    "        self.gen += 1\n",
    "        print(\"generation: %d | loss: %f\"%(self.gen,nn_base.loss(base.forward(xtr,self.population[0]),ytr)))\n",
    "        \n",
    "    def culture_score(self,w,xtr,ytr):\n",
    "        pred = base.forward(xtr,w)\n",
    "        a = sum(ytr==1) #True count\n",
    "        b = sum(pred[np.where(ytr==1)]>0.5) #True positive count\n",
    "        return b/a\n",
    "    \n",
    "    def culture_influence(self,pop,best):\n",
    "        pop1 = copy.deepcopy(pop)\n",
    "        for w in pop1:\n",
    "            for j in range(len(w)):\n",
    "                w[j] += np.random.choice([0,1],w[j].shape,p=[0.8,0.2]) * best[j]\n",
    "        return pop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENETIC\n",
      "CULTURAL\n"
     ]
    }
   ],
   "source": [
    "cult = cultural(base,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 1 | loss: 0.707446\n",
      "generation: 2 | loss: 0.066374\n",
      "generation: 3 | loss: 0.065195\n",
      "generation: 4 | loss: 0.065180\n",
      "generation: 5 | loss: 0.065178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/1634064413.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 6 | loss: 0.065177\n",
      "generation: 7 | loss: 0.065174\n",
      "generation: 8 | loss: 0.065169\n",
      "generation: 9 | loss: 0.065165\n",
      "generation: 10 | loss: 0.065126\n",
      "generation: 11 | loss: 0.064886\n",
      "generation: 12 | loss: 0.064816\n",
      "generation: 13 | loss: 0.064293\n",
      "generation: 14 | loss: 0.063703\n",
      "generation: 15 | loss: 0.062618\n",
      "generation: 16 | loss: 0.060902\n",
      "generation: 17 | loss: 0.059159\n",
      "generation: 18 | loss: 0.054297\n",
      "generation: 19 | loss: 0.053253\n",
      "generation: 20 | loss: 0.048763\n",
      "generation: 21 | loss: 0.043985\n",
      "generation: 22 | loss: 0.043985\n",
      "generation: 23 | loss: 0.043796\n",
      "generation: 24 | loss: 0.043796\n",
      "generation: 25 | loss: 0.041245\n",
      "generation: 26 | loss: 0.041245\n",
      "generation: 27 | loss: 0.041245\n",
      "generation: 28 | loss: 0.041245\n",
      "generation: 29 | loss: 0.041245\n",
      "generation: 30 | loss: 0.041245\n",
      "generation: 31 | loss: 0.041245\n",
      "generation: 32 | loss: 0.041245\n",
      "generation: 33 | loss: 0.040196\n",
      "generation: 34 | loss: 0.040143\n",
      "generation: 35 | loss: 0.037670\n",
      "generation: 36 | loss: 0.037670\n",
      "generation: 37 | loss: 0.037512\n",
      "generation: 38 | loss: 0.037199\n",
      "generation: 39 | loss: 0.036882\n",
      "generation: 40 | loss: 0.036882\n",
      "generation: 41 | loss: 0.036882\n",
      "generation: 42 | loss: 0.036882\n",
      "generation: 43 | loss: 0.036882\n",
      "generation: 44 | loss: 0.036882\n",
      "generation: 45 | loss: 0.036882\n",
      "generation: 46 | loss: 0.036882\n",
      "generation: 47 | loss: 0.036882\n",
      "generation: 48 | loss: 0.036882\n",
      "generation: 49 | loss: 0.036882\n",
      "generation: 50 | loss: 0.036882\n",
      "generation: 51 | loss: 0.036882\n",
      "generation: 52 | loss: 0.036882\n",
      "generation: 53 | loss: 0.036882\n",
      "generation: 54 | loss: 0.036882\n",
      "generation: 55 | loss: 0.036793\n",
      "generation: 56 | loss: 0.036793\n",
      "generation: 57 | loss: 0.036761\n",
      "generation: 58 | loss: 0.036761\n",
      "generation: 59 | loss: 0.036761\n",
      "generation: 60 | loss: 0.036746\n",
      "generation: 61 | loss: 0.036746\n",
      "generation: 62 | loss: 0.036325\n",
      "generation: 63 | loss: 0.035211\n",
      "generation: 64 | loss: 0.035211\n",
      "generation: 65 | loss: 0.035211\n",
      "generation: 66 | loss: 0.035211\n",
      "generation: 67 | loss: 0.035211\n",
      "generation: 68 | loss: 0.035211\n",
      "generation: 69 | loss: 0.035211\n",
      "generation: 70 | loss: 0.035211\n",
      "generation: 71 | loss: 0.035211\n",
      "generation: 72 | loss: 0.035211\n",
      "generation: 73 | loss: 0.035211\n",
      "generation: 74 | loss: 0.035211\n",
      "generation: 75 | loss: 0.035211\n",
      "generation: 76 | loss: 0.035211\n",
      "generation: 77 | loss: 0.035211\n",
      "generation: 78 | loss: 0.035211\n",
      "generation: 79 | loss: 0.035211\n",
      "generation: 80 | loss: 0.035211\n",
      "generation: 81 | loss: 0.035211\n",
      "generation: 82 | loss: 0.035211\n",
      "generation: 83 | loss: 0.035211\n",
      "generation: 84 | loss: 0.035211\n",
      "generation: 85 | loss: 0.035211\n",
      "generation: 86 | loss: 0.035211\n",
      "generation: 87 | loss: 0.035211\n",
      "generation: 88 | loss: 0.035211\n",
      "generation: 89 | loss: 0.035211\n",
      "generation: 90 | loss: 0.035211\n",
      "generation: 91 | loss: 0.035211\n",
      "generation: 92 | loss: 0.035211\n",
      "generation: 93 | loss: 0.035211\n",
      "generation: 94 | loss: 0.035211\n",
      "generation: 95 | loss: 0.035211\n",
      "generation: 96 | loss: 0.035211\n",
      "generation: 97 | loss: 0.035211\n",
      "generation: 98 | loss: 0.035211\n",
      "generation: 99 | loss: 0.035211\n",
      "generation: 100 | loss: 0.035211\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    cult.move(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/1634064413.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1073,   50],\n",
       "       [  18,   26]], dtype=int64)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = (base.forward(xtst,cult.population[0])>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1123\n",
      "           1       0.34      0.59      0.43        44\n",
      "\n",
      "    accuracy                           0.94      1167\n",
      "   macro avg       0.66      0.77      0.70      1167\n",
      "weighted avg       0.96      0.94      0.95      1167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - Ant Colony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class antcolony:\n",
    "    def __init__(self,base,n_ants):\n",
    "        print(\"ACO\")\n",
    "        self.base = base\n",
    "        self.n_ants = n_ants\n",
    "        self.population = [base.random_weights() for i in range(n_ants)]\n",
    "        self.pheromone = [[np.ones(i.shape) for i in self.population[0]] for j in range(n_ants)]\n",
    "        self.gen = 0\n",
    "        self.loss = lambda w,xtr,ytr : nn_base.loss(base.forward(xtr,w),ytr)\n",
    "        \n",
    "    def move(self,xtr,ytr):\n",
    "\n",
    "        for i in self.population:\n",
    "            ind = np.arange(self.n_ants)\n",
    "            bestind = np.random.choice(ind,p = self.popacc)\n",
    "            self.updateant(i,bestind)\n",
    "            \n",
    "        self.gen += 1\n",
    "        print(\"generation: %d | acc: %f\"%(self.gen,max(self.popacc)))\n",
    "            \n",
    "    def updateant(self,ant,bestind):\n",
    "        best = self.population[bestind]\n",
    "        val = 1/self.popacc[bestind]\n",
    "        for i in range(len(ant)):\n",
    "            ant[i] += val*best[i]*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACO\n"
     ]
    }
   ],
   "source": [
    "aco = antcolony(base,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 1 | acc: 0.934815\n",
      "generation: 2 | acc: 0.934820\n",
      "generation: 3 | acc: 0.934820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/1634064413.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 4 | acc: 0.934820\n",
      "generation: 5 | acc: 0.934820\n",
      "generation: 6 | acc: 0.934820\n",
      "generation: 7 | acc: 0.934820\n",
      "generation: 8 | acc: 0.934820\n",
      "generation: 9 | acc: 0.934820\n",
      "generation: 10 | acc: 0.934820\n",
      "generation: 11 | acc: 0.934820\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/3848397712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0maco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/2346395442.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(self, xtr, ytr)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoploss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generation: %d | acc: %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoploss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/2346395442.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoploss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generation: %d | acc: %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoploss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/2346395442.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(w, xtr, ytr)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpheromone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnn_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/1634064413.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ip, weights)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#bias layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#linear combination and activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    aco.move(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAYANK~1\\AppData\\Local\\Temp/ipykernel_11880/1634064413.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1080,   39],\n",
       "       [  11,   37]], dtype=int64)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = (base.forward(xtst,cult.population[0])>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1119\n",
      "           1       0.49      0.77      0.60        48\n",
      "\n",
      "    accuracy                           0.96      1167\n",
      "   macro avg       0.74      0.87      0.79      1167\n",
      "weighted avg       0.97      0.96      0.96      1167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
